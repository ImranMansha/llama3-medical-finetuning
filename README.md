# LLaMA 3 Fine-Tuning for Medical Chain-of-Thought Reasoning (Unsloth + Hugging Face)

This project demonstrates how to fine-tune the [LLaMA 3 (3B) Instruct model](https://huggingface.co/meta-llama/Meta-Llama-3-3B-Instruct) using a Chain-of-Thought dataset specific to medical reasoning, with **Unsloth**, **PEFT (QLoRA)**, and **Hugging Face** integration.

## ğŸš€ Project Overview

- ğŸ”¬ Dataset: [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT)
- ğŸ§  Model: Meta-LLaMA 3 (3B) Instruct
- ğŸ› ï¸ Fine-Tuning: SFT with PEFT using Unsloth
- ğŸ“Š Evaluation: ROUGE-L scores before and after fine-tuning
- ğŸ§ª Trained on: Google Colab

## ğŸ“ Files

- `llama3_finetune_medical_cot.ipynb` â€“ Full notebook with training pipeline
- `README.md` â€“ Project summary

## ğŸ“ˆ ROUGE-L Evaluation

- **Before Fine-Tuning**: `0.3052`
- **After Fine-Tuning**: `0.3052` (slight fluctuation due to short training)

## âœ… Steps Included

1. Model loading (Unsloth)
2. Dataset loading and formatting
3. PEFT configuration (QLoRA)
4. Training with `SFTTrainer`
5. ROUGE-L evaluation
6. Saving and uploading to Hugging Face Hub

## ğŸ¤– Model on Hugging Face Hub

ğŸ“Œ https://huggingface.co/imranmansha/llama3-medical-finetuned

## ğŸ§  Creator

- **Name:** Imran Mansha
- **LinkedIn:** [[Your LinkedIn link here](https://www.linkedin.com/in/imranmansha/)]
- **YouTube Walkthrough:** [[YouTube link here](https://youtu.be/ogoe71cpUe4?si=rT-agQQK_QkZmBr2)]

---

## ğŸ“ License

This project is licensed under the MIT License.
